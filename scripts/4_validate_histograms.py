#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
4_validate_histograms.py
------------------------
Performs histogram-based Jensen-Shannon Divergence (JSD) validation by comparing
velocity magnitude distributions from a "real" (reference) dataset against a
"predicted" dataset.

Pipeline:
 1. Loads configuration (YAML + CLI).
 2. Identifies common CFD cases between the real and predicted data directories.
 3. For each case:
    a. Loads time series of velocity magnitudes from all frames in the real dataset.
       The point coordinates from the first real frame are used as a common reference grid.
    b. Loads time series of velocity magnitudes from all frames in the predicted dataset.
       These are interpolated to the common reference grid if necessary.
    c. Computes JSD per point based on the histograms of these magnitude time series.
    d. Saves the JSD values as a heatmap in a new VTK file.
 4. Logs mean JSD metrics per case and overall (console and optionally W&B).

This script operates on existing VTK files and does not run any models itself.

Usage:
    python scripts/4_validate_histograms.py \
        --real-data-dir path/to/reference_vtk_series \
        --pred-data-dir path/to/predicted_vtk_series \
        --output-dir outputs/my_jsd_validation_results \
        --config path/to/config.yaml [options]

Example:
    python scripts/4_validate_histograms.py \
        --real-data-dir outputs/noisy_data/CFD_Ubend_other_val_noisy \
        --pred-data-dir outputs/my_flownet_run/validation_predictions/FlowNet \
        --output-dir outputs/jsd_flownet_vs_noisy_real \
        --model-name-prefix FlowNet_vs_NoisyReal
"""

import argparse
from pathlib import Path
import sys
import numpy as np
import shutil # For cleaning up test dirs if needed

# Ensure the src directory is in the Python path
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))

from src.cfd_gnn.validation import load_velocity_series # Using the one from validation.py
from src.cfd_gnn.metrics import compute_jsd_histograms
from src.cfd_gnn.utils import (
    load_config, get_run_name, initialize_wandb, write_vtk_with_fields,
    sort_frames_by_number
)

def main():
    parser = argparse.ArgumentParser(description="Perform JSD histogram validation between two VTK datasets.")
    parser.add_argument(
        "--config", type=str, default=None, help="Path to a YAML configuration file."
    )
    parser.add_argument(
        "--real-data-dir", type=str, required=True,
        help="Directory of the 'real' (reference) CFD cases (e.g., ground truth or noisy input)."
    )
    parser.add_argument(
        "--pred-data-dir", type=str, required=True,
        help="Directory of the 'predicted' CFD cases (VTKs generated by a model)."
    )
    parser.add_argument(
        "--output-dir", type=str, required=True,
        help="Directory to save JSD heatmap VTK files and summary."
    )
    parser.add_argument(
        "--velocity-key-real", type=str,
        help="VTK point_data key for velocity in real dataset (e.g., 'U' or 'U_noisy')."
    )
    parser.add_argument(
        "--velocity-key-pred", type=str,
        help="VTK point_data key for velocity in predicted dataset (e.g., 'velocity')."
    )
    parser.add_argument(
        "--num-bins", type=int, help="Number of bins for histograms."
    )
    parser.add_argument(
        "--cases", type=str, nargs="*",
        help="Specific cases to validate. Default: common sUbend* cases in both dirs."
    )
    parser.add_argument(
        "--model-name-prefix", type=str, default="JSD_Validation",
        help="Prefix for W&B logging and output subdirectories (e.g., 'FlowNet_JSD')."
    )
    parser.add_argument(
        "--run-name", type=str, default=None,
        help="Optional W&B run name. If None, generated from model-name-prefix."
    )
    parser.add_argument(
        "--no-wandb", action="store_true", help="Disable Weights & Biases logging."
    )

    args = parser.parse_args()

    # --- 1. Configuration Loading ---
    default_cfg_path = project_root / "config" / "default_config.yaml"
    cfg = load_config(args.config or default_cfg_path)

    # Prioritize CLI args
    real_data_dir = Path(args.real_data_dir)
    pred_data_dir = Path(args.pred_data_dir)
    output_dir_base = Path(args.output_dir)

    vel_key_real = args.velocity_key_real or cfg.get("velocity_key", "U") + cfg.get("noisy_velocity_key_suffix","") # Sensible default
    vel_key_pred = args.velocity_key_pred or cfg.get("predicted_velocity_key", "velocity")
    num_bins = args.num_bins if args.num_bins is not None else cfg.get("nbins", cfg.get("BINS",32)) # from global config

    model_name_prefix = args.model_name_prefix
    output_dir_jsd_run = output_dir_base / model_name_prefix
    output_dir_jsd_run.mkdir(parents=True, exist_ok=True)

    print(f"JSD Validation Run: {model_name_prefix}")
    print(f"  Real (Reference) Data: {real_data_dir} (using key '{vel_key_real}')")
    print(f"  Predicted Data: {pred_data_dir} (using key '{vel_key_pred}')")
    print(f"  JSD VTK Outputs: {output_dir_jsd_run}")
    print(f"  Histogram Bins: {num_bins}")

    # --- W&B Initialization (Optional) ---
    jsd_run_name = get_run_name(args.run_name or f"jsdval_{model_name_prefix}")
    if args.no_wandb:
        wandb_run = None
    else:
        wandb_run = initialize_wandb(
            config={**cfg, **vars(args)},
            run_name=jsd_run_name,
            project_name=cfg.get("wandb_project") + "_JSD_Validation" if cfg.get("wandb_project") else "CFD_GNN_JSD_Validation",
            output_dir=output_dir_jsd_run # W&B logs within this run's JSD output
        )

    # --- 2. Identify Common Cases ---
    real_case_dirs = {d.name: d for d in real_data_dir.iterdir() if d.is_dir() and d.name.startswith("sUbend")}
    pred_case_dirs = {d.name: d for d in pred_data_dir.iterdir() if d.is_dir() and d.name.startswith("sUbend")}

    common_case_names = sorted(list(set(real_case_dirs.keys()) & set(pred_case_dirs.keys())))

    if args.cases: # Filter by user-specified cases if provided
        specified_cases = set(args.cases)
        common_case_names = [name for name in common_case_names if name in specified_cases]

    if not common_case_names:
        print("Error: No common sUbend* cases found between real and predicted data directories.")
        sys.exit(1)
    print(f"Found {len(common_case_names)} common cases for JSD validation: {common_case_names}")

    overall_jsd_means = []
    overall_jsd_stds = []

    # --- 3. Process Each Case ---
    for case_name in common_case_names:
        print(f"\n--- Processing Case for JSD: {case_name} ---")

        current_real_cfd_dir = real_case_dirs[case_name] / "CFD"
        current_pred_cfd_dir = pred_case_dirs[case_name] / "CFD"

        real_vtk_files = sort_frames_by_number(list(current_real_cfd_dir.glob("*.vtk")))
        pred_vtk_files = sort_frames_by_number(list(current_pred_cfd_dir.glob("*.vtk")))

        if not real_vtk_files:
            print(f"  Warning: No VTK files in real data dir {current_real_cfd_dir}. Skipping case.")
            continue
        if not pred_vtk_files:
            print(f"  Warning: No VTK files in predicted data dir {current_pred_cfd_dir}. Skipping case.")
            continue

        if len(real_vtk_files) != len(pred_vtk_files):
            print(f"  Warning: Mismatch in number of frames for case {case_name}. "
                  f"Real: {len(real_vtk_files)}, Pred: {len(pred_vtk_files)}. Using min count.")
            min_frames = min(len(real_vtk_files), len(pred_vtk_files))
            real_vtk_files = real_vtk_files[:min_frames]
            pred_vtk_files = pred_vtk_files[:min_frames]
            if min_frames == 0:
                print("  Zero frames to process after count matching. Skipping case.")
                continue

        print(f"  Processing {len(real_vtk_files)} frames for case {case_name}.")

        try:
            # a. Load real velocity series (and get reference points from first frame)
            print(f"  Loading REAL velocity series (key: '{vel_key_real}')...")
            real_vel_series, ref_points_for_jsd = load_velocity_series(
                real_vtk_files, velocity_key=vel_key_real
            )
            real_mag_series = np.linalg.norm(real_vel_series, axis=2) # [T, N]

            # b. Load predicted velocity series (interpolating to ref_points_for_jsd)
            print(f"  Loading PRED velocity series (key: '{vel_key_pred}')...")
            pred_vel_series, _ = load_velocity_series(
                pred_vtk_files,
                velocity_key=vel_key_pred,
                interpolate_to_points=ref_points_for_jsd # Ensure interpolation
            )
            pred_mag_series = np.linalg.norm(pred_vel_series, axis=2) # [T, N]

            if real_mag_series.shape != pred_mag_series.shape:
                print(f"  Error: Shape mismatch after loading series for {case_name}. "
                      f"Real: {real_mag_series.shape}, Pred: {pred_mag_series.shape}. Skipping JSD for case.")
                continue
            if real_mag_series.size == 0:
                print(f"  Error: Loaded magnitude series are empty for {case_name}. Skipping JSD.")
                continue


            # c. Compute JSD
            print(f"  Computing JSD (Num bins: {num_bins})...")
            jsd_values_per_point, _, _ = compute_jsd_histograms(
                real_mag_series, pred_mag_series, num_bins=num_bins
            )

            # d. Save JSD heatmap VTK
            case_jsd_output_dir = output_dir_jsd_run / case_name / "CFD"
            case_jsd_output_dir.mkdir(parents=True, exist_ok=True)
            jsd_vtk_path = case_jsd_output_dir / f"{case_name}_hist_jsd.vtk"

            write_vtk_with_fields(
                jsd_vtk_path,
                points=ref_points_for_jsd,
                point_data={"JSD": jsd_values_per_point.astype(np.float32)}
            )
            print(f"  Saved JSD heatmap to: {jsd_vtk_path}")

            # Log metrics for this case
            mean_jsd_case = float(np.mean(jsd_values_per_point))
            std_jsd_case = float(np.std(jsd_values_per_point))
            overall_jsd_means.append(mean_jsd_case)
            overall_jsd_stds.append(std_jsd_case) # Storing stds, though averaging them directly isn't standard

            print(f"  Case {case_name}: Mean JSD = {mean_jsd_case:.4e}, Std JSD = {std_jsd_case:.4e}")
            if wandb_run:
                wandb_run.log({
                    f"{model_name_prefix}/{case_name}/JSD_mean": mean_jsd_case,
                    f"{model_name_prefix}/{case_name}/JSD_std": std_jsd_case,
                    # f"{model_name_prefix}/{case_name}/JSD_values": wandb.Histogram(jsd_values_per_point)
                })
                # art_case_jsd = wandb.Artifact(f"jsd_heatmap_{model_name_prefix}_{case_name}", type="jsd_result")
                # art_case_jsd.add_file(str(jsd_vtk_path))
                # wandb_run.log_artifact(art_case_jsd)


        except Exception as e:
            print(f"  Error processing case {case_name}: {e}")
            # import traceback
            # traceback.print_exc()
            continue # Move to next case

    # --- 4. Overall Summary ---
    print("\n--- Overall JSD Validation Summary ---")
    if overall_jsd_means:
        final_mean_jsd = float(np.mean(overall_jsd_means))
        # For std of stds, or overall std if all points were one big array: need careful thought.
        # For now, just reporting mean of means.
        print(f"  Average of Mean JSDs across all cases: {final_mean_jsd:.4e} (from {len(overall_jsd_means)} cases)")
        if wandb_run:
            wandb_run.summary[f"{model_name_prefix}/Overall_JSD_Mean_of_Means"] = final_mean_jsd
    else:
        print("  No JSD metrics were computed across cases.")

    if wandb_run:
        # Log the output directory as an artifact if it contains results
        if any(output_dir_jsd_run.rglob('*.vtk')): # Check if any VTK files were produced
            art_all_jsd = wandb.Artifact(f"JSD_Results_{model_name_prefix}", type="dataset_jsd_outputs")
            art_all_jsd.add_dir(str(output_dir_jsd_run))
            wandb_run.log_artifact(art_all_jsd)
        wandb_run.finish()

    print("\nJSD Histogram Validation script finished.")
    print(f"All JSD outputs saved in: {output_dir_jsd_run}")

if __name__ == "__main__":
    main()
